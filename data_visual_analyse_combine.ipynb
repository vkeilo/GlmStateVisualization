{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 字数统计任务隐藏状态参数可视化分析"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据可视化处理"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 针对当前数据文件结构，设计一个用于取用数据的类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from IPython.display import clear_output\n",
    "from config_parse import VisualConfig\n",
    "visualconfig = VisualConfig(\"./visual_config.json\")\n",
    "\n",
    "class HidDataFetch():\n",
    "    def __init__(self, hid_datas_path, task_pattern) -> None:\n",
    "        self.config = visualconfig\n",
    "        self.task_pattern = task_pattern\n",
    "        self.hid_datas_path = hid_datas_path\n",
    "        self.dialogues_num = self.count_dirs(self.hid_datas_path)\n",
    "        print(\"dialogues_num:\", self.dialogues_num)\n",
    "        self.task_prompts = None\n",
    "        self.dialogues = []\n",
    "        self.tag_list = []\n",
    "        self.datas = []\n",
    "        self.fetch_all_dialogues()\n",
    "        self.init_tags()\n",
    "        self.init_task_prompts()\n",
    "        # self.fetch_all_datas()\n",
    "\n",
    "    # 加载所有种类的任务描述\n",
    "    def init_task_prompts(self):\n",
    "        with open(self.config.role_setting_prompt_json, 'r', encoding='utf-8') as f:\n",
    "            role_setting_prompts = json.load(f)\n",
    "        self.task_prompts = role_setting_prompts[self.task_pattern]\n",
    "\n",
    "    # 获取特定序号任务的task_prompt序号\n",
    "    def get_task_prompt_index(self, index):\n",
    "        tmp_task_prompt = self.dialogues[index]['dialogues'][0][\"content\"]\n",
    "        return self.task_prompts.index(tmp_task_prompt)\n",
    "    \n",
    "    # 获取全部任务的task_prompt序号列表\n",
    "    def get_all_task_prompt_index(self):\n",
    "        tmp_task_prompts = []\n",
    "        for i in range(self.dialogues_num):\n",
    "            tmp_task_prompts.append(self.get_task_prompt_index(i))\n",
    "        return tmp_task_prompts\n",
    "\n",
    "    # 将所有dialogue.txt读取整合\n",
    "    def fetch_all_dialogues(self):\n",
    "        for i in range(self.dialogues_num):\n",
    "            self.dialogues.append(self.load_dialogue_by_index(i))\n",
    "    # 将所有隐藏状态参数读取整合\n",
    "    def fetch_all_datas(self):\n",
    "        for i in range(self.dialogues_num):\n",
    "            self.datas.append(self.load_data_by_index(i))\n",
    "\n",
    "    # 读取对应index的dialogue.txt\n",
    "    def load_dialogue_by_index(self, index):\n",
    "        with open(self.hid_datas_path + \"/\" + str(index) + \"/dialogue.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "            dialogue = json.load(f)\n",
    "\n",
    "    # 提取出所有的tag\n",
    "    def init_tags(self):\n",
    "        for diagolue in self.dialogues:\n",
    "            self.tag_list.append(diagolue['tag'])\n",
    "\n",
    "    # 统计文件夹中下有多少文件和文件夹\n",
    "    def count_dirs(self, path):\n",
    "        return len(os.listdir(path))\n",
    "    \n",
    "    # 从硬盘中读取对应的dialogue.txt\n",
    "    def load_dialogue_by_index(self, index):\n",
    "        if index >= self.dialogues_num:\n",
    "            print(\"index out of range\")\n",
    "            return None\n",
    "        hid_data_path = os.path.join(self.hid_datas_path, str(index), 'dialogue.txt')\n",
    "        # print(hid_data_path)\n",
    "        hid_data = {}\n",
    "        with open(hid_data_path, 'r', encoding='utf-8') as f:\n",
    "            hid_data = json.load(f)\n",
    "        return hid_data\n",
    "    \n",
    "    # 获取某index对应的完整的dialogue.txt\n",
    "    def fetch_by_index(self, index):\n",
    "        return self.dialogues[index]\n",
    "    \n",
    "    # 获取某index的tag\n",
    "    def fetch_tag_by_index(self, index):\n",
    "        if index >= self.dialogues_num:\n",
    "            print(\"index out of range\")\n",
    "            return None\n",
    "        return self.dialogues[index]['tag']\n",
    "    \n",
    "    # 获取某index对应的完整的对话内容\n",
    "    def fetch_dialogue_by_index(self, index):\n",
    "        if index >= self.dialogues_num:\n",
    "            print(\"index out of range\")\n",
    "            return None\n",
    "        return self.dialogues[index]['dialogues']\n",
    "\n",
    "    # 获取符合某个tag的所有index\n",
    "    def fetch_index_list_by_tag(self, tag):\n",
    "        return [index for index in range(self.dialogues_num) if self.dialogues[index]['tag'] == tag]\n",
    "\n",
    "    # 获取某个index下的所有data\n",
    "    def load_data_by_index(self, index):\n",
    "        data_dir_path = os.path.join(self.hid_datas_path, str(index))\n",
    "        datas = []\n",
    "        for file in sorted(os.listdir(data_dir_path)):\n",
    "            if file.endswith(\".npz\"):\n",
    "                data_path = os.path.join(data_dir_path, file)\n",
    "                data_f = np.load(data_path)\n",
    "                datas.append(np.array(list(data_f.values())))\n",
    "                data_f.close()\n",
    "        return datas\n",
    "    \n",
    "    # 获取某个index下的特定的data\n",
    "    def load_special_data(self, path_index, round, speaker, file_index, layer = None):\n",
    "        filename = self.get_special_filename(path_index, round, speaker, file_index)\n",
    "        data_dir_path = os.path.join(self.hid_datas_path, str(path_index))\n",
    "        data_path = os.path.join(data_dir_path, filename)\n",
    "        data_f = np.load(data_path)\n",
    "        datas = np.array(list(data_f.values()))\n",
    "        data_f.close()\n",
    "        if layer is not None:\n",
    "            return np.array([datas[layer]])\n",
    "        return datas\n",
    "    \n",
    "    # 获取特定隐藏层的file_index\n",
    "    def get_special_filename(self, path_index, round, speaker, file_index):\n",
    "        data_dir_path = os.path.join(self.hid_datas_path, str(path_index))\n",
    "        filename_list = []\n",
    "        user_filename_list = []\n",
    "        assistant_filename_list = []\n",
    "        tmp_round = 0\n",
    "        for file in sorted(os.listdir(data_dir_path)):\n",
    "            if file.endswith(\".npz\"):\n",
    "                filename_list.append(file)\n",
    "        base_size = os.path.getsize(os.path.join(data_dir_path, filename_list[1]))\n",
    "        for file in filename_list:\n",
    "            file_size = os.path.getsize(os.path.join(data_dir_path, file))\n",
    "            if file_size > base_size:\n",
    "                user_filename_list.append([file])\n",
    "                tmp_round = tmp_round + 1\n",
    "            else:\n",
    "                if tmp_round > len(assistant_filename_list): \n",
    "                    assistant_filename_list.append([file])\n",
    "                else:\n",
    "                    assistant_filename_list[tmp_round-1].append(file)\n",
    "        if speaker == \"user\":\n",
    "            return user_filename_list[round][file_index]\n",
    "        elif speaker == \"assistant\":\n",
    "            return assistant_filename_list[round][file_index]\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    # 获取user输入文本开始对应的index\n",
    "    def get_use_text_index_by_index(self, index):\n",
    "        user_index_list = [index for index, element in enumerate(self.load_data_by_index(index)) if element.shape[1] > 1]\n",
    "        return user_index_list\n",
    "        \n",
    "    # 分情况载入特定数据\n",
    "    def load_one_state_by_special_position(self, index, round, speaker, token_index_range, layer = None):\n",
    "        layer_num = 29 if layer is None else 1\n",
    "\n",
    "\n",
    "        if speaker == \"user\":\n",
    "            if type(token_index_range) is int:\n",
    "                tmp_data = self.load_special_data(index,round,speaker,0, layer)[:, token_index_range, :, :]\n",
    "                tmp_data = tmp_data.reshape(layer_num, 4096)\n",
    "            else:\n",
    "                tmp_data = self.load_special_data(index,round,speaker,0, layer)[:, token_index_range[0]:None if token_index_range[1] == 0 else token_index_range[1], :, :]\n",
    "                tmp_data = tmp_data.reshape(layer_num, token_index_range[1]-token_index_range[0],4096)\n",
    "                tmp_data = np.transpose(tmp_data, (1, 0, 2))\n",
    "        elif speaker == \"assistant\":\n",
    "            if type(token_index_range) is int:\n",
    "                tmp_data = self.load_special_data(index,round,speaker,token_index_range, layer)\n",
    "                tmp_data = tmp_data.reshape(layer_num, 4096)\n",
    "            else:\n",
    "                tmp_data = self.load_special_data(index, round, speaker, token_index_range[0], layer)\n",
    "                tmp_data = tmp_data.reshape(1, layer_num, 4096)\n",
    "                for i in range(token_index_range[0]+1, token_index_range[1], -1 if token_index_range[0] else 1):\n",
    "                    tmp_data = np.concatenate((tmp_data, self.load_special_data(index,round,speaker,i, layer).reshape(1, layer_num, 4096)), axis=0)\n",
    "        tmp_label = str(self.fetch_tag_by_index(index))\n",
    "        return index, tmp_data, tmp_label  # 返回索引和数据\n",
    "    \n",
    "    # 获取全部数据中特定位置（最后一次用户输入后）的特定隐藏层参数\n",
    "    def load_all_state_by_special_position(self, round, speaker, token_index_range, layer = None):\n",
    "\n",
    "\n",
    "        # 初始化列表\n",
    "        datas = [None] * len(self.dialogues)\n",
    "        labels = [None] * len(self.dialogues)\n",
    "        count = 0\n",
    "        with ThreadPoolExecutor(max_workers=64) as executor:\n",
    "            futures = [executor.submit(self.load_one_state_by_special_position, i, round, speaker, token_index_range, layer) for i in range(len(self.dialogues))]\n",
    "            total_dialogues = len(self.dialogues)\n",
    "            for future in as_completed(futures):\n",
    "                i, tmp_data, tmp_label = future.result()\n",
    "                datas[i] = tmp_data  # Use the index to insert at the correct position\n",
    "                labels[i] = tmp_label\n",
    "                count += 1\n",
    "                # Calculate the percentage of completion\n",
    "                percent_complete = (count / total_dialogues) * 100\n",
    "                # Print the real-time percentage progress\n",
    "                if count % 10 == 0:\n",
    "                    clear_output(wait=True)\n",
    "                    print(f\"Progress: {percent_complete:.2f}% Complete ({count}/{total_dialogues})\")\n",
    "\n",
    "        return np.array(datas), np.array(labels)\n",
    "        # return datas, labels\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dialogues_num: 1034\n",
      "dialogues_num: 1000\n"
     ]
    }
   ],
   "source": [
    "trans_data_fetcher = HidDataFetch(\"./datas/translator\", \"translator\")\n",
    "count_data_fetcher = HidDataFetch(\"./datas/counter\", \"counter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100.00% Complete (1000/1000)\n"
     ]
    }
   ],
   "source": [
    "trans_datas,trans_labels = trans_data_fetcher.load_all_state_by_special_position(-1, 'user', -2)\n",
    "count_datas,count_labels= count_data_fetcher.load_all_state_by_special_position(-1, 'user', -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_task_kind_list = trans_data_fetcher.get_all_task_prompt_index()\n",
    "count_task_kind_list = count_data_fetcher.get_all_task_prompt_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取目标数据"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里，我们首先尝试获取了所有任务中，用户将最后一次任务完整输入后，最后一层transformer隐藏层的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只取最后一层隐藏层输出\n",
    "trans_datas_layer29 = np.array([data[28] for data in trans_datas])\n",
    "count_datas_layer29 = np.array([data[28] for data in count_datas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取labels，没能够成功识别的，默认为正确完成翻译任务\n",
    "trans_labels_int = np.array([int(y) if y=='0' or y=='1' else 0  for y in trans_labels])\n",
    "count_labels_int = np.array([int(y)+2 if y=='0' or y=='1' else 2  for y in count_labels])\n",
    "trans_task_kind_list_int = np.array([int(y) for y in trans_task_kind_list])\n",
    "count_task_kind_list_int = np.array([int(y)+10 for y in count_task_kind_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas_layer29 = np.concatenate((trans_datas_layer29, count_datas_layer29), axis=0)\n",
    "labels_int = np.concatenate((trans_labels_int, count_labels_int), axis=0)\n",
    "task_kind_list = np.concatenate((trans_task_kind_list_int, count_task_kind_list_int), axis=0)\n",
    "data_id = np.array(range(len(datas_layer29)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 准备数据三维可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def data_draw_3d(dime_re_tool, datas, labels, color_map = None, hover_data = {}):\n",
    "    # 应用t-SNE降维到三维\n",
    "    # tsne = TSNE(n_components=3, perplexity=30, random_state=42)\n",
    "    data_tsne = dime_re_tool.fit_transform(datas)\n",
    "    # 将降维后的数据和标签转换为DataFrame\n",
    "    df = pd.DataFrame(data_tsne, columns=['x', 'y', 'z'])\n",
    "    df['fig_label'] = labels.astype(str)  # 添加标签列\n",
    "    for key, datas in hover_data.items():\n",
    "        print(key)\n",
    "        df[key] = datas\n",
    "    # 使用Plotly创建交互式三维散点图\n",
    "    fig = px.scatter_3d(df, x='x', y='y', z='z',\n",
    "                        color='fig_label', \n",
    "                        labels={'label': 'Label'},\n",
    "                        color_discrete_map=color_map,\n",
    "                        hover_data=['fig_label']+[key for key in hover_data],\n",
    "                        title='t-SNE 3D Visualization')\n",
    "    fig.update_traces(marker=dict(size=3))\n",
    "    # fig.show()\n",
    "    fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind\n",
      "data_id\n"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=3, perplexity=30, random_state=42)\n",
    "data_draw_3d(tsne, datas_layer29, labels_int, color_map = None, hover_data = {\"kind\": task_kind_list, \"data_id\":data_id})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 应用t-SNE降维到三维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind\n",
      "data_id\n"
     ]
    }
   ],
   "source": [
    "tsne = TSNE(n_components=3, perplexity=30, random_state=42)\n",
    "data_draw_3d(tsne, datas_layer29, labels_int, color_map = None, hover_data = {\"kind\": task_kind_list, \"data_id\":data_id})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 应用主成分分析（PCA）降维到三维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind\n",
      "data_id\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3, random_state=42)\n",
    "data_draw_3d(pca, datas_layer29, labels_int, color_map = None, hover_data = {\"kind\": task_kind_list, \"data_id\":data_id})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 应用多维缩放（MDS）降维到三维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\data_analyse\\lib\\site-packages\\sklearn\\manifold\\_mds.py:298: FutureWarning:\n",
      "\n",
      "The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind\n",
      "data_id\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import MDS\n",
    "\n",
    "# 应用MDS降维到三维\n",
    "mds = MDS(n_components=3, random_state=42)\n",
    "data_draw_3d(mds, datas_layer29, labels_int, color_map = None, hover_data = {\"kind\": task_kind_list, \"data_id\":data_id})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 接下来尝试动态可视化"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 首先还是数据准备\n",
    "显然，多数电脑在进行隐藏层序列可视化的时候，只能加载个别层数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 99.61% Complete (1030/1034)\n"
     ]
    }
   ],
   "source": [
    "trans_datas_ml,trans_labels_ml = trans_data_fetcher.load_all_state_by_special_position(-1, 'user', (-15, 0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_datas_ml = trans_datas_ml.reshape(1034,trans_datas_ml.shape[1],4096)\n",
    "trans_datas_ml = trans_datas_ml.transpose(1,0,2)\n",
    "trans_labels_ml_int = np.array([int(y) if y=='0' or y=='1' else 0  for y in trans_labels_ml])\n",
    "trans_datas_prompt_kind_list = np.array(trans_data_fetcher.get_all_task_prompt_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.decomposition import PCA\n",
    "def data_draw_3d_by_tokens(dime_re_tool, datas_array, labels_int_list, color_map = None, hover_data = {}):\n",
    "    fig = make_subplots(rows=1, cols=1, specs=[[{'type': 'scatter3d'}]])\n",
    "    ori_shape = datas_array.shape\n",
    "    trans_datas_3d_all = dime_re_tool.fit_transform(datas_array.reshape(-1,4096))\n",
    "    trans_datas_3d_all_dvid = trans_datas_3d_all.reshape(ori_shape[0],ori_shape[1],3)\n",
    "    for time_step in range(trans_datas_3d_all_dvid.shape[0]):\n",
    "        indices = np.array(range(trans_datas_3d_all_dvid.shape[1]))\n",
    "        # Filter data points by class\n",
    "        class_indices = {}\n",
    "        unique_kinds = set(labels_int_list)\n",
    "        # 遍历labels_int_list列表的唯一值\n",
    "        for kind in unique_kinds:\n",
    "            class_indices[kind] = labels_int_list == kind\n",
    "\n",
    "\n",
    "        for kind in unique_kinds:\n",
    "            hovertexts = [\n",
    "                '<br>'.join([f'{key}: {hover_data[key][idx]}' for key in hover_data])\n",
    "                for idx in indices[class_indices[kind]]\n",
    "            ]\n",
    "            # Data for class 0 at the current time step\n",
    "            fig.add_trace(\n",
    "                go.Scatter3d(\n",
    "                    x=trans_datas_3d_all_dvid[time_step, class_indices[kind], 0],\n",
    "                    y=trans_datas_3d_all_dvid[time_step, class_indices[kind], 1],\n",
    "                    z=trans_datas_3d_all_dvid[time_step, class_indices[kind], 2],\n",
    "                    mode='markers',\n",
    "                    marker=dict(size=3),\n",
    "                    hovertext=hovertexts,\n",
    "                    name=f'Class {kind}',\n",
    "                    visible=(time_step == 0)  # Only the first time step is visible initially\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    # Create the slider steps, one for each time step\n",
    "    steps = []\n",
    "    for i in range(trans_datas_3d_all_dvid.shape[0]):\n",
    "        step = dict(\n",
    "            method='update',\n",
    "            args=[{'visible': [False] * trans_datas_3d_all_dvid.shape[0] * 2}],\n",
    "            label=f'Time step {i+1}'\n",
    "        )\n",
    "        step['args'][0]['visible'][i*2] = True  # Toggle i-th trace to \"visible\"\n",
    "        step['args'][0]['visible'][i*2 + 1] = True  # Toggle i-th trace to \"visible\"\n",
    "        steps.append(step)\n",
    "\n",
    "    sliders = [dict(\n",
    "        active=0,\n",
    "        currentvalue={\"prefix\": \"Time step: \"},\n",
    "        pad={\"t\": 50},\n",
    "        steps=steps\n",
    "    )]\n",
    "\n",
    "    fig.update_layout(\n",
    "        sliders=sliders\n",
    "    )\n",
    "\n",
    "    # Set axis properties to make them visible\n",
    "    fig.update_layout(scene=dict(\n",
    "        xaxis=dict(\n",
    "            title='X Axis',\n",
    "            showbackground=True,\n",
    "            backgroundcolor=\"rgb(230, 230,230)\",\n",
    "            gridcolor=\"white\",\n",
    "            showline=True,\n",
    "            zeroline=True,\n",
    "            showgrid=True,\n",
    "            showticklabels=True\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Y Axis',\n",
    "            showbackground=True,\n",
    "            backgroundcolor=\"rgb(230, 230,230)\",\n",
    "            gridcolor=\"white\",\n",
    "            showline=True,\n",
    "            zeroline=True,\n",
    "            showgrid=True,\n",
    "            showticklabels=True\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            title='Z Axis',\n",
    "            showbackground=True,\n",
    "            backgroundcolor=\"rgb(230, 230,230)\",\n",
    "            gridcolor=\"white\",\n",
    "            showline=True,\n",
    "            zeroline=True,\n",
    "            showgrid=True,\n",
    "            showticklabels=True\n",
    "        ),\n",
    "        aspectmode='cube'  # This can be \"data\", \"cube\", \"auto\", \"manual\"\n",
    "    ))\n",
    "    fig.show(renderer=\"browser\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3, random_state=42)\n",
    "tsne = TSNE(n_components=3, perplexity=30, random_state=42)\n",
    "# tmpdata = tsne.fit_transform(trans_datas_ml.reshape(-1,4096))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_draw_3d_by_tokens(pca, trans_datas_ml, trans_labels_ml_int, color_map = None, hover_data = {\"id\":np.array(range(1034)),\"prompt_kind\":trans_datas_prompt_kind_list})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
